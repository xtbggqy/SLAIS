# API 配置
PUBMED_API_BASE_URL="https://eutils.ncbi.nlm.nih.gov/entrez/eutils/" # PubMed API基础URL
# DEFAULT_REQUEST_TIMEOUT="30.0" # 全局默认请求超时时间 (秒)

# 大语言模型 API 配置 (强烈建议通过此处配置模型名称、API密钥、基础URL等)
OPENAI_API_KEY="" # 您的API密钥
OPENAI_API_MODEL=qwen-turbo # 使用的模型名称（如gpt-4o、gpt-3.5-turbo、qwen-turbo等，支持OpenAI或兼容API）
OPENAI_API_BASE_URL="https://dashscope.aliyuncs.com/compatible-mode/v1" # API端点（如用OpenAI官方则留空或填官方地址）
OPENAI_TEMPERATURE="0.1" # 模型温度，控制输出的随机性

# 大语言模型 API 配置（文本分析专用）
OPENAI_API_KEY="" # 用于文本分析的API密钥
OPENAI_API_MODEL=qwen-turbo # 用于文本分析的模型名称（如gpt-4o、gpt-3.5-turbo、qwen-turbo等）
OPENAI_API_BASE_URL="https://dashscope.aliyuncs.com/compatible-mode/v1" # 文本分析API端点
OPENAI_TEMPERATURE="0.1" # 文本分析模型温度

# 图像理解大模型 API 配置（图片内容分析专用）
IMAGE_LLM_API_KEY="" # 用于图片分析的API密钥
IMAGE_LLM_API_MODEL=qwen-vl-plus # 用于图片分析的模型名称（如qwen-vl-plus、gpt-4o、minigpt4等）
IMAGE_LLM_API_BASE_URL="https://dashscope.aliyuncs.com/compatible-mode/v1" # 图片分析API端点
IMAGE_LLM_TEMPERATURE="0.1" # 图片分析模型温度

# 可选模型列表（逗号分隔，供Web界面下拉选择用）
TEXT_MODEL_CHOICES="qwen-turbo,qwen-plus,qwen-max,qwen3-235b-a22b"
IMAGE_MODEL_CHOICES="qwen-vl-plus,qwen-vl-max,llama-4-maverick-17b-128e-instruct,llama-4-scout-17b-16e-instruct"

# 模型价格配置（每1000token，单位元），格式：模型名:prompt单价:completion单价，多模型用逗号分隔
MODEL_COSTS="qwen-turbo:0.0003:0.0006,qwen-plus:0.0008:0.002,qwen-max:0.0024:0.0096"
# NCBI 配置
NCBI_EMAIL="qqy14@gmail.com" # 您的邮箱地址 (NCBI API要求)
RELATED_ARTICLES_YEARS_BACK=10 # 检索相关文献时回溯的年数
RELATED_ARTICLES_MAX=50 # 获取相关文章的最大数量
# PUBMED_TOOL_NAME="slais_pubmed_client" # PubMed API tool name (通常使用默认值)
# PUBMED_EFETCH_BATCH_SIZE="200" # PubMed efetch API 批量大小 (通常使用默认值)
# PUBMED_REQUEST_TIMEOUT="45.0" # PubMed API 请求超时时间 (秒) (通常使用默认值)
# PUBMED_REQUEST_DELAY="0.35" # PubMed API 请求之间的延迟（秒） (通常使用默认值)
# PUBMED_RETRY_COUNT="3" # PubMed API 请求重试次数 (通常使用默认值)

# Semantic Scholar API 配置
SEMANTIC_SCHOLAR_API_KEY="" # 您的Semantic Scholar API密钥 (可选, 但推荐以获取更高请求速率)
SEMANTIC_SCHOLAR_API_BATCH_SIZE=25 # 每批次请求的DOI数量 (适当设置可减少请求超时风险)
SEMANTIC_SCHOLAR_REQUEST_DELAY=0.2 # 批次间延迟时间(秒)
# SEMANTIC_SCHOLAR_RETRY_COUNT="3" # API请求重试次数 (通常使用默认值)
# SEMANTIC_SCHOLAR_TIMEOUT="30.0" # API请求超时时间 (通常使用默认值)

# PDF路径配置
PDF_INPUT_DIR="pdfs" # 存放输入PDF文件的目录
DEFAULT_PDF_PATH="pdfs/darwin.pdf" # 未指定输入时默认处理的PDF文件

# Markdown输出子目录（如不设置则自动为 <PDF文件名>_markdown）
# MARKDOWN_SUBDIR=darwin_markdown

# 文章DOI配置 (重要：替换为实际要分析的文献DOI)
ARTICLE_DOI="10.1126/science.aao4593" 

# 输出目录配置
OUTPUT_BASE_DIR="output" # 分析结果的输出根目录

# 缓存配置 (当前未使用，但为未来规划保留)
CACHE_DIR="cache" # 缓存文件存放目录
CACHE_EXPIRY_DAYS="30" # 缓存有效期 (天)

# 日志配置
LOG_LEVEL="INFO" # 日志级别 (DEBUG, INFO, WARNING, ERROR, CRITICAL)
LOG_DIR="logs" # 日志文件存放目录
# LOG_FILE 不在此处设置，由config.py动态生成带时间戳的文件名

# 分析配置
MAX_CONTENT_CHARS_FOR_LLM=500000 # 传递给LLM进行分析的最大内容字符数
MAX_QUESTIONS_TO_GENERATE=25 # LLM生成问答对的最大数量 (可以根据需要调整)
